{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alice9th/Python_Challenges/blob/master/16_1_2_PRACTICE_Training_a_AllConvolutional_CNN_on_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzNIOw9IqeRI"
      },
      "source": [
        "# CNN on CIFAR 10\n",
        "\n",
        "We've used a fully connected NN with many layers to classify the 10 CIFAR10 classes. However, its performance was not very good (please go back and check its accuracy, as well as how many parameters the network had).\n",
        "\n",
        "By adding convolutional layers to the beginning of a neural network, we can create a CNN that will be able to achieve betters results with less parameters.\n",
        "\n",
        "IMPORTANT: We highly recommend using a GPU for this exercise. The training of the models takes a significant amount of time. You should write down the parameters and results of every run you make to compare and determine the best model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-gox-8IbVrQ"
      },
      "source": [
        "## 1. AllConvolutional Network\n",
        "\n",
        "In this case, we'll use the `All-CNN-C` variant of [the AllConvolutional network](https://arxiv.org/abs/1412.6806). This network was one of the first deep networks that proposed using only convolution operations to classify images. The network does not use MaxPooling layers; instead it relies on Convolutions with `strides=(2,2)` to downsample the feature maps. As with VGG, AllConvolutional relies on `3x3` convolutions and employs the strategy of duplicating the number of filters every time a subsampling operation reduces by 1/4 the number of pixels of the feature maps.\n",
        "\n",
        "Note that the AllConvolutional model does not include a Flatten layer after the final convolutional layer, but instead relies on a combination of two special layers to generate the scores for each class.\n",
        "\n",
        "First, a `Conv2D` layer with `10` feature maps as outputs and `1x1` convolutions converts the `192` feature maps into `10xHxW` scores. Then a [GlobalAveragePooling2D](https://keras.io/api/layers/pooling_layers/global_average_pooling2d) layer averages out the `HxW` spatial dimensions, leaving just `10` scores, one per class. Finally, the original article used a softmax directly over these `10` class scores. Instead, we propose you add a `Dense` layer with `softmax` activation to perform the final classification. This combination of Global Average Pooling with Dense layers has become a standard practice since it adds a bit of prediction power to the model.\n",
        "\n",
        "**Hint:** your network should only have around 1M parameters.\n",
        "**Hint:** Use `padding=same` to maintain make all intermediate spatial dimensions powers of 2 (32,16,8, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9nQGOMbNqdvA",
        "outputId": "3293d9c1-818d-41f2-dfcd-694fd4bd8657"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = None\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # YOUR IMPLEMENTATION HERE (START)\n",
        "\n",
        "    # YOUR IMPLEMENTATION HERE (END)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LX5C448DTD6"
      },
      "source": [
        "## 2. Data loading\n",
        "\n",
        "You can load the data for the MNIST dataset with a single keras function: `tf.keras.datasets.cifar10.load_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miAy_GdYDSsd"
      },
      "outputs": [],
      "source": [
        "# Normalize data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# YOUR IMPLEMENTATION HERE (START)\n",
        "\n",
        "\n",
        "# YOUR IMPLEMENTATION HERE (END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSE5EWWME9aq"
      },
      "source": [
        "# 3. Training the model\n",
        "\n",
        "CNNs are trained just the same as any NN model; you'll need to `compile` the model with an optimizer, a loss function, and some metrics to monitor the performance of the model.\n",
        "\n",
        "Since this is a classification problem, you'll use a `categorical_crossentropy` loss, but check the encoding of the outputs to decide if it is `sparse` (labels) or dense (one-hot encoding).\n",
        "\n",
        "\n",
        "Afterwards, you can just call the `fit` function as usual. Training for 30 epochs with a batch size of 128 should suffice to obtain a reasonably good accuracy on the test set (~79%). Save the result of the `fit` function to a variable named `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPZP_Z_FE8p8"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "\n",
        "# YOUR IMPLEMENTATION HERE (START)\n",
        "\n",
        "\n",
        "# YOUR IMPLEMENTATION HERE (END)\n",
        "\n",
        "history = model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=30, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk2OmpsPfP9B"
      },
      "source": [
        "#4. Analyzing the accuracy curves\n",
        "\n",
        "Let's visualize the accuracy for the train (`accuracy`) and test (`val_accuracy`) during training.\n",
        "\n",
        "* Is the training accuracy always increasing? And the training loss?\n",
        "* What about the test accuracy/loss?\n",
        "* Is the model underfitting o overfitting?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45LgqmlwvR_f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'], label='Train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'Test accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(history.history['loss'], label='Train loss')\n",
        "  plt.plot(history.history['val_loss'], label = 'Test loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH0NwwLHkN1b"
      },
      "source": [
        "# 5. Adding Dropout egularization\n",
        "\n",
        "Your network has many parameters! Therefore, it's likely that if you overtrain it you'll overfit the training set. To counter that, you can try adding a `Dropout` layer before the last Dense layer, introducing a reasonably low amount of noise. We suggest trying low dropout proabilities, in the order of `0.1` to `0.3`. Define a new model, now with Dropout, and train it again.\n",
        "\n",
        "* What happens if you increase too much the probability?\n",
        "* Can you find a dropout probability that increases the final test set accuracy?\n",
        "* Try adding a bit of dropout between convolutions as well. Is the model more sensitive to higher dropout probabilities in this lower layers? Why?\n",
        "* Do you need to adjust the number of epochs to obtain a good performance?\n",
        "* Extra: You could also try using L1/L2 regularization and compare the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06-6eE_4lMIU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = None\n",
        "# YOUR IMPLEMENTATION HERE (START)\n",
        "\n",
        "# YOUR IMPLEMENTATION HERE (END)\n",
        "history = model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=30, batch_size=128)\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmA9kjejEbtx"
      },
      "source": [
        "# 6. Data Augmentation\n",
        "\n",
        "Data augmentation (DA) is a common and realtively cheap way to increase model performance.\n",
        "\n",
        "In Keras, DA transformations can be added to the model definition simply as additional layers. They will only run while training the model (`fit` and friends), but not during evaluation or other scenarios.\n",
        "\n",
        "Try adding [random rotatiosn](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation), [flips](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip) and other [random DA layers](https://keras.io/api/layers/preprocessing_layers/image_augmentation/) between the input layer and the first convolutional layer. Then you can simply train your model as usual.\n",
        "\n",
        "Note that you'll probably need to train the model a bit more than in the previous cases.\n",
        "\n",
        "Note: This way of applying DA is relatively new in Keras and differs significantly from the previous API (replaced in ~2020) that used the `ImageDataGenerator` class, so beware when browsing documentation and tutorials.\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "* Try using extreme DA transformations, such as cropping more than 50% of the image. What effect does that have on the model and the train/test performance?\n",
        "* By default, data augmentation is only applied to the training set, but the test set is not augmented. Why do you think that is? In which cases would it make sense to apply DA also to the test set?.\n",
        "* Given your previous answers, think of 3 transformations that would not help the model perform better on the test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKgAwsTUEbGj"
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "# YOUR IMPLEMENTATION HERE (START)\n",
        "\n",
        "\n",
        "])\n",
        "# YOUR IMPLEMENTATION HERE (END)\n",
        "history = model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=30, batch_size=128)\n",
        "plot_history(history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}